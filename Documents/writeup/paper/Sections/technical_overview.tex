%!TEX root = ../main.tex

\section{Technical Overview of Results}
\label{sec:technical_overview}

\subsection{Protocols Implemented}

In this work we implemented a few distributed protocols of the PRF introduced by Boneh et. Al  \cite{darkmatter}:

$PRF_k(x) = R \times (K \times x \mod 2)  \mod 3 $

where $R$ is a randomization matrix in $Z_3$, $K$ is an $m \times n$ key and $x$ is an $n$-length vector. Specifically, we present a new protocol for implementing this PRF. The protocol uses a shared input and output which provides improved performance over the original protocol described in \cite{darkmatter}. For context, we also implement the original protocol \cite{darkmatter} . We also introduce an improved OPRF (Oblivious PRF) protocol, in which one party has the input and one has the key. Below are  details of the protocols.

\subsubsection{PRF}

\paragraph{notations:} below are the notations we use to describe the protocols: \\
$K$ is the key, represented by an $m \times n$ matrix \\
$x$ is the input, represented by an $n$ size vector \\
$R_x, r_k$ - pre-shared randomness for key $K$ and input $x$ \\
$r$ - random vector in $Z_3$]
We use capital letters for matrices, and $\vec{x}$ notation for vectors \\


\paragraph{Original Distributed Input Distributed Output (DIDO) PRF Protocol}

The protocol was introduced in \cite{darkmatter}. The main details of the protocols are described below (\ref{2PartyDarkMatter}). In this setting, both the input and the key are secret shared additively between the two parties. Both the protocol presented in this paper and the original protocol are two-party PRFs.

%add  a description of the protocol



\begin{algorithm}
\caption{2-Party dark matter PRF}
\label{2PartyDarkMatter}


	Input: ${K_{m\times n} }(i)$ and $\vec{Inp}(i_n)$ key and user input of each user,\\
	$(i = 1...2, n,m = 256)$\\ 
	Output: user 1: $\vec{K} \times x + \vec{r}$\\
	user2: $\neg \vec{r}$\\   %SVec = salt vectorx`
	
		\begin{algorithmic}
			
\STATE Preprocessing:

		Output: 	user 1: $\vec{R_a}, \vec{r_b}$ - pre-shared randomness \\
						 user 2: $\vec{r_x} $- pre-share randomness \\

\STATE Stage\ 1: calculate $a \times b \plus c$

	input: user 1: ${\vec{A}, \vec{b}, {\vec R_a}, \vec{r_b} } $ \\
			  user 2: ${\vec{x}, \vec{r_x},  \vec{z} }$ \\

	  \begin{enumerate}
	
	\item user 2 $\vec{m_x} = \vec{x} -\vec{r_x}  \rightarrow  $  user 1
	
	\item user 1  $ \leftarrow   \vec{M_a} =  \vec{A} - \vec{r_A}   $ user 2
	
	\item user 2 $ \vec{m_b} = \vec{R_a} \times \vec{m_x} + \vec{b}  - \vec{r_b}  \rightarrow $ user 1
\end{enumerate}

	Output: $user 1: \vec{\neg b} $  \\
                 $user 2: \vec{M_a} \times \vec{x} + \vec{m_b} + \vec{z} = \vec{A} \vec{x} + \vec{b}$ \\

\STATE Stage\ 2: Oblivious Transfer
input: 	 user 1:  $\vec{r_1}, \vec{r_2}, \vec{r_a}, \vec{r_b}$ - vectors in $Z_3$
			user 2:  $\vec{x}, \vec{r_x}$ - vectors in $Z_2$, $\vec{z} $ - vector in $Z_3$
			
			
			\begin{enumerate}
				\item user 1  $ \leftarrow   \vec{m_x} = \vec{x} \oplus \vec{r_x}$   user 2
			 
				\item user 1:  $  \vec{m_1} = \vec(\neg m_x)  \vec{r_a} + \vec{m_x} \vec{r_b} + \vec{r_1}   \rightarrow $   user 2
				
				\item user 1:  $  \vec{m_2} = \vec(m_x)  \vec{r_a} + \vec{\neg m_x} \vec{r_b} + \vec{r_2}  \rightarrow $   user 2
				
				
			\end{enumerate}
			
output:  user 2: $\vec{w}:= \vec{x} \times \vec{m_2}+ \neg \vec{x}  \times \vec{m_1} - \vec{z}$
					

\STATE stage 3: $Z_3$ randomization  

\end{algorithmic}

\end{algorithm}




%add table with parameters, including communication

\paragraph{Our improved (DIDO) PRF protocol}

\begin{algorithm}
	\caption{2-Party DSISK PRF}
	\begin{algorithmic}
		
		\STATE Preprocessing
		
		\STATE Stage 1: calculate $a \times b \plus c$
		
		\STATE Stage 2: Oblivious Transfer
		
		\STATE stage 3: $Z_3$ randomization  
		
	\end{algorithmic}
\end{algorithm}



%add  a description of the protocol

%add table with parameters, including communication

\subsection{OPRF}
This is a new OPRF protocol, which improved the performance over the original OPRF protocol descirbed in \cite{darkmatter}. In this setting, one party has the input and another party has the key.

\begin{algorithm}
	\caption{2-Party oPRF}
	\begin{algorithmic}
		
		\STATE Preprocessing
		
		\STATE Stage\ 1: calculate $a \times b \plus c$
		
		\STATE Stage\ 2: Oblivious Transfer
		
		\STATE stage 3: $Z_3$ randomization  
		
	\end{algorithmic}
\end{algorithm}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\subsection{Parameters}
The input variable to the PRF functions are the key $K$ which is of size $m \times n$ and each input is a vector of size $n$. 
To save storage space, the key was implemented as a Toeplitz matrix, requiring $2 \cdot n$ bits of storage space.
In phase 3 of the algorithm, a randomization matrix is used which is of size $r \times n = 81 \times 256$, resulting in entropy of 128 bits.

\subsection{Optimizations}

\subsubsection{packing in $Z_2$}

Bit slicing: this bit-wise packing technique was used to optimize the run-time, each 64 bits were represented by a word. Since each key is of size $m \times n$ and each input is a vactor of size $n$, it is possible to pack each 64 rows into $m$ words. This may result in time saving of up to $\times 64$ of the run-time.

\subsubsection{Packing in $Z_3$}

To optimize the randomization in $Z_3$, which requires a matrix-vector multiplication in the last phase of the PRF calculation, we implement two optimization methods:

\paragraph{Bit slicing:} this was done by representing a vector over $Z_3$  as two binary vectors - one LSB's and one MSB's. 

A few operations, such as addition, subtraction and multiplication mod 3 required extra calculations. One of the properties that were utilized to implement this was:\\
mult-by-2 $\mod 3  \leftrightarrow$ negation $ \mod 3 \leftrightarrow$ swap the MSB and LSB\\

Such a vector is sometimes being represented as a vector of $2 \times n$ bits. One example is when this vector is sent as an input to the Oblivious Transfer mechanism. 
The algorithms can be found in ~\cref{alg:algpack1,alg:algpack2,alg:algpack3,alg:algpack4}.

% TODO: replace with a table

\begin{algorithm}
	\caption{Addition in $Z_3$}
		\label{alg:algpack1}  Item 1:
		input: $\vec{l_1}, \vec{m_1}$ - LSB and MSB vectors of value 1  \\
		  	  	$\vec{l_2}, \vec{m_2}$ - LSB and MSB vectors of value 2
		
\begin{enumerate}

	\item $\vec{T} = (\vec{l_1} \lor \vec{m_2}) \oplus (\vec{l_2} | \vec{m_1})$;
	\item $MSB_{res} = ( \vec{l_1} \lor \vec{l_2} ) \oplus  \vec{T} $;
	\item $LSB_{res} = (\vec{m_1} \lor \vec{m_2} ) \oplus \vec{T} $;
	
	\end{enumerate}
	
\end{algorithm}

\begin{algorithm}
		\caption{Subtraction in $Z_3$}
		\label{alg:algpack2} Item 2:

	
		input: $\vec{l_1}, \vec{m_1}$ - LSB and LSB vectors of value 1  \\
                  $\vec{l_2}, \vec{m_2}$ - LSB and LSB vectors of value 2
                  
\begin{enumerate}

	\item $\vec{T} = (\vec{l_1} | \vec{l_2}) \land (\vec{m_2} | \vec{m_1})$;
	\item $MSB_{res} = (\vec{l_1} | \vec{m_2} ) \land \vec{T}$;
    \item $LSB_{res} = (\vec{m_1} | \vec{l_2} ) \land \vec{T}$;
\end{enumerate}
	
	\end{algorithm}



\begin{algorithm}
			\caption{Multiplication of two trinary vectors $Z_3$}
		\label{alg:algpack3} Item 3:

		
				input: $\vec{l_1}, \vec{m_1}$ - LSB and LSB vectors of value 1  \\
		$\vec{l_2}, \vec{m_2}$ - LSB and LSB vectors of value 2
		
			\begin{enumerate}
	\item  $\vec{LSB_{res}} = ((\vec{l_1} \land (\vec{l_2}) \land     ((\vec{m_1} \land (\vec{m_2})       $
	\item	$\vec{MSB_{res}}= ((\vec{l_1} \land (\vec{m_2}) \land     ((\vec{m_1} \land (\vec{l_2})       $

	\end{enumerate}
		
	\end{algorithm}

\begin{algorithm}
		\caption{Mux implementation of two trinary vectors $Z_3$}
			\label{alg:algpack4} 

	
		input:   $\vec{l_1}, \vec{m_1}$ - LSB and LSB vectors of value 1  \\
					$\vec{l_2}, \vec{m_2}$ - LSB and LSB vectors of value 2
					$\vec{select}$ - binary vector

	\begin{enumerate}
		\item for each word $i$
	    \item $\vec{LSB[i]} =( \vec{l_2} \land \vec{s[i]}) | (\vec{l_1} \land \vec{\neg s[i]})$
	    		    \item $\vec{MSB[i]} =( \vec{m_2} \land \vec{s[i]}) | (\vec{m_1} \land \vec{\neg s[i]})$
		
	\end{enumerate}
	
\end{algorithm}



\paragraph{Integer packing:} this was explored as an alternative to the bit slicing.  Since each number is a trinary number, the multiplication of each row by the output vector can be any number between -256 to 256. To explore this option, we represented each number by 9 bits, and packed 7 numbers into each word. This was expected to result in time saving of up to $\times 7$. Testing this option indeed proved to be significantly slower than the first method of packing. We therefore continued using the first packing method of packing instead.
Note: Since each trinary number can be either 0,1 or 2, we can add up to 255 numbers and never exceed 510. Moreover, if we take a random sample, we can add 256 numbers and the probability of carryover is negligible. We use this to multiply a packed trinary vector with a trinary matrix with 256 columns (see algorithm below).
	
	$x_0 \dots x_6 \epsilon Z_3 = {0,1,2}$
	
	$ \rightarrow x = \sum_{i=0}^{6} (512^i) \times c_i, x_i \epsilon [0 ... (2^(64)-1)]$


%TODO: IS THIS CORRECT? CHECK AND CORRECT

\paragraph{Using a lookup table:} To further optimize the run-time, we created a lookup table to replace the matrix-vector multiplication. To this end, the randomization matrix is assumed to be constant and divided into 16 matrices of size $81 \times 16$. A lookup table of size $16 x 2^{256}$ is created during the pre-processing stage. During runtime, the input is divided to MSB and LSB, and each consecutive 16 bits (16 rows in the matrix) are used as separate input to the lookup table.





\section{Analysis}

Table \ref{CommCosts} includes the computation and communication results for the different protocol.

%TODO: ADD comutation and communication results

\begin{table}[htbp]
	\label{CommCosts}
	%[h]
	\begin{center}
		%\begin{minipage}{10cm}
		\begin{tabular}{|c|c|c|c|c|}
			\hline
			\textbf{Protocol} & \textbf{Packed }  &  \textbf{$Z_3$ lookup table} & \textbf{Computation} & Communication Costs \\
			\hline
			\hline
			\textbf{Centralized}  & N  & N  &  & 0	 \\
			\hline
			\textbf{Centralized} & Y  &  N & &	 \\
			\hline
			\textbf{Original (DIDO) PRF protocol} & Y	& N &   & 	\\
			\hline
			\textbf{Our  (DIDO) PRF algorithm} & Y & N &	 &  \\
			\hline
			\textbf{Our  (DIDO) PRF algorithm} & Y & Y &  &  	\\
			\hline
			\textbf{Our OPRF} & Y & N &  &  	\\
			\hline
			\textbf{Our OPRF} & Y & Y &  &  	\\
			\hline
			\textbf{Discrete log-based PRF} &  - & - &  &  \\
			\hline
			
		\end{tabular}
		
		\vspace{-1mm}
		\caption{Run-time of different protocols}
		\label{RuntimeTable}
		%\end{minipage}
	\end{center}
	\vspace{-5mm}
\end{table}

\section{Benchmarking}

We compare our run-time to discrete-log based PRFs. To this end, we use the lib sodium library \cite{LibSodium}. The library uses elliptic curve 252 bits, and includes a function that performs scalar multiplication ('crypto\_scalarmult\_ed25519').


\section{Experimental Results}

The system was tested on AWS environment, on Ubuntu Server 18.04 with t2.medium. For testing, the code was run in a loop 1000 times. Below are run-time results. The results include both centralized and distributed version. The packing indicates both the $Z_2$ and $Z_3$ packing.

%add table
\begin{table}[htbp]
	%[h]
	\begin{center}
		%\begin{minipage}{10cm}
		\begin{tabular}{|c|c|c|c|c|}
			\hline
			\textbf{Protocol} & \textbf{Packed }  &  \textbf{$Z_3$ lookup table} & \textbf{Rounds/sec} & Runtime($\mu$ sec)\\
			\hline
			\hline
			\textbf{Centralized}  & N  & N  &  50K&	20.2 \\
			\hline
			\textbf{Centralized} & Y  &  N & 65.4K &	18.5 \\
			\hline
			\textbf{Original distributed dark matter} & Y	& N &  24K & 40.56	\\
			\hline
			\textbf{This protocol} & Y & N &	49K &  20.20\\
			\hline
			\textbf{This protocol} & Y & Y & 83K &  12.00	\\
			\hline
			\textbf{oPRF} & Y & N & 53K &  18.66	\\
			\hline
			\textbf{oPRF} & Y & Y & 11.76K &  8.50	\\
			\hline
			\textbf{Discrete log-based PRF} &  - & - & 34K & 29.56 \\
			\hline
			
		\end{tabular}
		
		\vspace{-1mm}
		\caption{Run-time of different protocols}
		\label{RuntimeTable}
		%\end{minipage}
	\end{center}
	\vspace{-5mm}
\end{table}







